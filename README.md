# README.md
 
Deep Learning Exploration

This lab was very extensive and required us to create four different deep learning models. The first model was based on an IMDB dataset of reviews, with the goal of classifying them into negative or positive categories. Essentially, this data would be used to train the model to perform this task accurately. The dataset consisted of 50,000 different reviews, which were then split into halves: one half for training and the other for testing. We utilized two hidden layer models with the relu activation function, and employed the sigmoid activation function in our output layer. Our model ended up overfitting with an accuracy of 0.88; we were encouraged to change the optimizer and loss function to improve our results. Unfortunately, these changes only worsened our accuracy score.

The second model was a deep learning model intended to determine whether a song would go viral based on several features such as bpm, danceability, liveliness, etc. The data we used contained the top 100 songs on Spotify for 2023 along with a variety of features. In retrospect, this data was far too small to create an effective model. We used the relu and sigmoid activation functions again, with binary crossentropy for our loss function and the Adam optimizer. Our model returned an extremely high accuracy rating due to the fact that we considered only the top songs in the 100 to be viral. This expected a song to hit 2.8 trillion streams to be considered viral, which is the average number of streams for the top 10 songs. By doing this, it was just really good at predicting that a song would not go viral most of the time.

Our third model aimed to predict passenger airline satisfaction and returned an accuracy of 56%. Lastly, our final model was used to predict whether a patient had diabetes based on their health attributes. This model achieved an accuracy rating of 70.78%, which is fair, but nowhere near the minimum total error we were aiming for.

This lab enhanced our ability to code deep learning models and also conduct feature engineering, further improving our understanding and confidence in creating our own deep learning models based on our selected data.
